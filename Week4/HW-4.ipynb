{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this homework, we will use Credit Card Data from book \"Econometric Analysis\".\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\n",
    "```\n",
    "The goal of this homework is to inspect the output of different evaluation metrics by creating a classification model (target column `card`). \n",
    "\n",
    "\n",
    "## Preparation\n",
    "\n",
    "* Create the target variable by mapping `yes` to 1 and `no` to 0. \n",
    "* Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` function for that with `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-06 17:48:49--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 73250 (72K) [text/plain]\n",
      "Saving to: ‘AER_credit_card_data.csv’\n",
      "\n",
      "AER_credit_card_dat 100%[===================>]  71,53K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2023-04-06 17:48:49 (5,50 MB/s) - ‘AER_credit_card_data.csv’ saved [73250/73250]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.58333</td>\n",
       "      <td>4.5660</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>23.91667</td>\n",
       "      <td>3.1920</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>40.58333</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>101.298300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>26.996670</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>48.25000</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.111619</td>\n",
       "      <td>344.157500</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "...   ...      ...       ...     ...       ...          ...   ...     ...   \n",
       "1314  yes        0  33.58333  4.5660  0.002146     7.333333   yes      no   \n",
       "1315   no        5  23.91667  3.1920  0.000376     0.000000    no      no   \n",
       "1316  yes        0  40.58333  4.6000  0.026513   101.298300   yes      no   \n",
       "1317  yes        0  32.83333  3.7000  0.008999    26.996670    no     yes   \n",
       "1318  yes        0  48.25000  3.7000  0.111619   344.157500   yes      no   \n",
       "\n",
       "      dependents  months  majorcards  active  \n",
       "0              3      54           1      12  \n",
       "1              3      34           1      13  \n",
       "2              4      58           1       5  \n",
       "3              0      25           1       7  \n",
       "4              2      64           1       5  \n",
       "...          ...     ...         ...     ...  \n",
       "1314           0      94           1      19  \n",
       "1315           3      12           1       5  \n",
       "1316           2       1           1       2  \n",
       "1317           0      60           1       7  \n",
       "1318           2       2           1       0  \n",
       "\n",
       "[1319 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AER_credit_card_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card',\n",
       " 'reports',\n",
       " 'age',\n",
       " 'income',\n",
       " 'share',\n",
       " 'expenditure',\n",
       " 'owner',\n",
       " 'selfemp',\n",
       " 'dependents',\n",
       " 'months',\n",
       " 'majorcards',\n",
       " 'active']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.card = (df.card == 'yes').astype(int)\n",
    "df.owner = (df.owner == 'yes').astype(int)\n",
    "df.selfemp = (df.selfemp == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.58333</td>\n",
       "      <td>4.5660</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23.91667</td>\n",
       "      <td>3.1920</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.58333</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>101.298300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>26.996670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.25000</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.111619</td>\n",
       "      <td>344.157500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      card  reports       age  income     share  expenditure  owner  selfemp  \\\n",
       "0        1        0  37.66667  4.5200  0.033270   124.983300      1        0   \n",
       "1        1        0  33.25000  2.4200  0.005217     9.854167      0        0   \n",
       "2        1        0  33.66667  4.5000  0.004156    15.000000      1        0   \n",
       "3        1        0  30.50000  2.5400  0.065214   137.869200      0        0   \n",
       "4        1        0  32.16667  9.7867  0.067051   546.503300      1        0   \n",
       "...    ...      ...       ...     ...       ...          ...    ...      ...   \n",
       "1314     1        0  33.58333  4.5660  0.002146     7.333333      1        0   \n",
       "1315     0        5  23.91667  3.1920  0.000376     0.000000      0        0   \n",
       "1316     1        0  40.58333  4.6000  0.026513   101.298300      1        0   \n",
       "1317     1        0  32.83333  3.7000  0.008999    26.996670      0        1   \n",
       "1318     1        0  48.25000  3.7000  0.111619   344.157500      1        0   \n",
       "\n",
       "      dependents  months  majorcards  active  \n",
       "0              3      54           1      12  \n",
       "1              3      34           1      13  \n",
       "2              4      58           1       5  \n",
       "3              0      25           1       7  \n",
       "4              2      64           1       5  \n",
       "...          ...     ...         ...     ...  \n",
       "1314           0      94           1      19  \n",
       "1315           3      12           1       5  \n",
       "1316           2       1           1       2  \n",
       "1317           0      60           1       7  \n",
       "1318           2       2           1       0  \n",
       "\n",
       "[1319 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.card.values\n",
    "y_val = df_val.card.values\n",
    "y_test = df_test.card.values\n",
    "\n",
    "del df_train['card']\n",
    "del df_val['card']\n",
    "del df_test['card']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the `card` variable.\n",
    "* Use the training dataset for that.\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['expenditure']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `reports`\n",
    "- `dependents`\n",
    "- `active`\n",
    "- `share`\n",
    "\n",
    "### $Ans = share$\n",
    "\n",
    "\n",
    "## Training the model\n",
    "\n",
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['reports',\n",
    " 'age',\n",
    " 'income',\n",
    " 'share',\n",
    " 'expenditure',\n",
    " 'owner',\n",
    " 'selfemp',\n",
    " 'dependents',\n",
    " 'months',\n",
    " 'majorcards',\n",
    " 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 11) (791,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# temp = df_train[[\"reports\",\"age\"]]\n",
    "temp = ['reports','age','income','share','expenditure','owner','selfemp','dependents','months','majorcards','active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reports: 0.7166629860689376\n",
      "age: 0.5240020979407055\n",
      "income: 0.5908049467233478\n",
      "share: 0.989183643423692\n",
      "expenditure: 0.991042345276873\n",
      "owner: 0.5856751136384548\n",
      "selfemp: 0.5097995914536521\n",
      "dependents: 0.5327757227773791\n",
      "months: 0.5294217780967629\n",
      "majorcards: 0.5343859842838476\n",
      "active: 0.6043173411362006\n"
     ]
    }
   ],
   "source": [
    "for i in temp:\n",
    "\n",
    "    if roc_auc_score(y_train, df_train[i]) < 0.5:\n",
    "        print(\"%s:\"%i,roc_auc_score(y_train, -df_train[i]))\n",
    "    else:\n",
    "        print(\"%s:\"%i,roc_auc_score(y_train, df_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val[numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "churn_decision = (y_pred >= 0.5)\n",
    "(y_val == churn_decision).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949923991773226"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.615\n",
    "- 0.515\n",
    "- 0.715\n",
    "- 0.995\n",
    "\n",
    "## $$ Ans \\approx 0.995 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(0,1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17cd24eb0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual_positive = (y_val == 1)\n",
    "actual_negative = (y_val == 0)\n",
    "\n",
    "t = np.arange(0,1,0.01)\n",
    "\n",
    "pre =[]\n",
    "rec = []\n",
    "\n",
    "for i in t:\n",
    "    predict_positive = (y_pred >= i)\n",
    "    predict_negative = (y_pred < i)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "\n",
    "    pre.append(p)\n",
    "    rec.append(r)\n",
    "\n",
    "\n",
    "plt.plot(t,pre)\n",
    "plt.plot(t,rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on the validation dataset on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.1\n",
    "* 0.3\n",
    "* 0.6\n",
    "* 0.8\n",
    "\n",
    "## $$ Ans \\approx 0.3 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing $F_1$:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01 using the validation set\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- 0.4\n",
    "- 0.6\n",
    "- 0.7\n",
    "\n",
    "## $$ Ans \\approx 0.4 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_positive = (y_val == 1)\n",
    "actual_negative = (y_val == 0)\n",
    "\n",
    "t = np.arange(0,1,0.01)\n",
    "\n",
    "pre =[]\n",
    "rec = []\n",
    "f1_score = []\n",
    "for i in t:\n",
    "    predict_positive = (y_pred >= i)\n",
    "    predict_negative = (y_pred < i)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2*(p*r)/(p+r)\n",
    "\n",
    "    f1_score.append((i,f1))\n",
    "\n",
    "    pre.append(p)\n",
    "    rec.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "\n",
    "best_score = None\n",
    "for i in f1_score:\n",
    "    \n",
    "    if i[1] > score:\n",
    "        score = i[1]\n",
    "        best_score = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32, 0.9832134292565947)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.8884210526315789),\n",
       " (0.01, 0.9254385964912281),\n",
       " (0.02, 0.9295154185022027),\n",
       " (0.03, 0.9483146067415731),\n",
       " (0.04, 0.9483146067415731),\n",
       " (0.05, 0.9504504504504505),\n",
       " (0.06, 0.9525959367945824),\n",
       " (0.07, 0.9545454545454546),\n",
       " (0.08, 0.9567198177676538),\n",
       " (0.09, 0.958904109589041),\n",
       " (0.1, 0.958904109589041),\n",
       " (0.11, 0.958904109589041),\n",
       " (0.12, 0.958904109589041),\n",
       " (0.13, 0.9633027522935779),\n",
       " (0.14, 0.9677419354838711),\n",
       " (0.15, 0.9722222222222221),\n",
       " (0.16, 0.9742388758782201),\n",
       " (0.17, 0.9765258215962441),\n",
       " (0.18, 0.9765258215962441),\n",
       " (0.19, 0.9788235294117645),\n",
       " (0.2, 0.9739952718676123),\n",
       " (0.21, 0.9715639810426541),\n",
       " (0.22, 0.9715639810426541),\n",
       " (0.23, 0.9715639810426541),\n",
       " (0.24, 0.9715639810426541),\n",
       " (0.25, 0.9715639810426541),\n",
       " (0.26, 0.9738717339667459),\n",
       " (0.27, 0.9738717339667459),\n",
       " (0.28, 0.9738717339667459),\n",
       " (0.29, 0.9761904761904763),\n",
       " (0.3, 0.9785202863961814),\n",
       " (0.31, 0.9808612440191389),\n",
       " (0.32, 0.9832134292565947),\n",
       " (0.33, 0.9832134292565947),\n",
       " (0.34, 0.9832134292565947),\n",
       " (0.35000000000000003, 0.9807692307692307),\n",
       " (0.36, 0.9807692307692307),\n",
       " (0.37, 0.9807692307692307),\n",
       " (0.38, 0.9807692307692307),\n",
       " (0.39, 0.9807692307692307),\n",
       " (0.4, 0.9807692307692307),\n",
       " (0.41000000000000003, 0.9807692307692307),\n",
       " (0.42, 0.9807692307692307),\n",
       " (0.43, 0.9807692307692307),\n",
       " (0.44, 0.9807692307692307),\n",
       " (0.45, 0.9807692307692307),\n",
       " (0.46, 0.9807692307692307),\n",
       " (0.47000000000000003, 0.9807692307692307),\n",
       " (0.48, 0.9807692307692307),\n",
       " (0.49, 0.9807692307692307),\n",
       " (0.5, 0.9807692307692307),\n",
       " (0.51, 0.9807692307692307),\n",
       " (0.52, 0.9807692307692307),\n",
       " (0.53, 0.9807692307692307),\n",
       " (0.54, 0.9807692307692307),\n",
       " (0.55, 0.9807692307692307),\n",
       " (0.56, 0.9807692307692307),\n",
       " (0.5700000000000001, 0.9807692307692307),\n",
       " (0.58, 0.9807692307692307),\n",
       " (0.59, 0.9807692307692307),\n",
       " (0.6, 0.9807692307692307),\n",
       " (0.61, 0.9807692307692307),\n",
       " (0.62, 0.9807692307692307),\n",
       " (0.63, 0.9807692307692307),\n",
       " (0.64, 0.9807692307692307),\n",
       " (0.65, 0.9807692307692307),\n",
       " (0.66, 0.9807692307692307),\n",
       " (0.67, 0.9807692307692307),\n",
       " (0.68, 0.9807692307692307),\n",
       " (0.6900000000000001, 0.9807692307692307),\n",
       " (0.7000000000000001, 0.9807692307692307),\n",
       " (0.71, 0.9807692307692307),\n",
       " (0.72, 0.9807692307692307),\n",
       " (0.73, 0.9807692307692307),\n",
       " (0.74, 0.9807692307692307),\n",
       " (0.75, 0.9807692307692307),\n",
       " (0.76, 0.9807692307692307),\n",
       " (0.77, 0.9807692307692307),\n",
       " (0.78, 0.9807692307692307),\n",
       " (0.79, 0.9807692307692307),\n",
       " (0.8, 0.9807692307692307),\n",
       " (0.81, 0.9807692307692307),\n",
       " (0.8200000000000001, 0.9807692307692307),\n",
       " (0.8300000000000001, 0.9807692307692307),\n",
       " (0.84, 0.9807692307692307),\n",
       " (0.85, 0.9807692307692307),\n",
       " (0.86, 0.9807692307692307),\n",
       " (0.87, 0.983132530120482),\n",
       " (0.88, 0.983132530120482),\n",
       " (0.89, 0.983132530120482),\n",
       " (0.9, 0.983132530120482),\n",
       " (0.91, 0.983132530120482),\n",
       " (0.92, 0.983132530120482),\n",
       " (0.93, 0.983132530120482),\n",
       " (0.9400000000000001, 0.983132530120482),\n",
       " (0.9500000000000001, 0.9806763285024155),\n",
       " (0.96, 0.9806763285024155),\n",
       " (0.97, 0.9806763285024155),\n",
       " (0.98, 0.9782082324455207),\n",
       " (0.99, 0.9732360097323601)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- 0.003\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.24\n",
    "\n",
    "## $$ Ans \\approx 0.003 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.card.values\n",
    "    y_val = df_val.card.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=1.0)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C=%s %.3f +- %.3f' % (\"1.0\", np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C\n",
    "\n",
    "## $$ C = 10 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cf4390178646b8b42bb5659d27a7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001 0.989 +- 0.007\n",
      "C=0.01 0.992 +- 0.006\n",
      "C=0.1 0.994 +- 0.005\n",
      "C=0.5 0.996 +- 0.003\n",
      "C=1 0.996 +- 0.003\n",
      "C=5 0.997 +- 0.003\n",
      "C=10 0.997 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.001, 0.01, 0.1, 0.5, 1, 5, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.card.values\n",
    "        y_val = df_val.card.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "416edea8700fbacc3898057af766aa9a1314eef5c4240d84c0ee9b6939676b4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
